veribles = ncol(df)
if (ceiling(detectCores()/2)>=veribles){cores <- (veribles-2)}
registerDoParallel(cores = cores)
}
# Prepering mtry_set if not given
if (is.null(mtry_set)){
mtry_set <- 1:4
mtry_set[1] <- floor(sqrt(ncol(df)))
if (mtry_set[1]>1){
mtry_set[2] <- ceiling(mtry_set[1]/2)
vector <- (mtry_set[1]:ncol(df))
mtry_set[3] <- floor(length(vector)/3)
mtry_set[4] <- floor(2*length(vector)/3)
}
else{
vector <- (mtry_set[1]:ncol(df))
mtry_set[2] <- floor(length(vector)/4)
mtry_set[3] <- floor(2*length(vector)/4)
mtry_set[4] <- floor(3*length(vector)/4)
}
}
# If parallel=TRUE
parallelize <- 'no'
if (parallel){
parallelize <-  'variables'}
if(cores<=1){parallelize <- 'no'}
if (optimize){
print(cores)
# Grid search using mean OBBerror
best_params <-  c(-11,-11)
best_OBB <- 10
for (i in ntree_set)
{
for (j in mtry_set){
skip_to_next <- FALSE
tryCatch({
iteration <-  mean(missForest(df,maxiter = maxiter,ntree = i,mtry = j,parallelize=parallelize,maxnodes = maxnodes,verbose = verbose)$OOBerror)
if (iteration<best_OBB){
best_OBB <- iteration
best_params[1] <- i
best_params[2] <- j
}
}, error = function(e) { skip_to_next <<- TRUE})
if(skip_to_next) { next }
}
}
#fianl imputation
final <- missForest(df,maxiter = maxiter,maxnodes = maxnodes,ntree = best_params[1],mtry = best_params[2],parallelize=parallelize,verbose = verbose)$ximp
}
if (!optimize){
if (is.null(mtry)){
final <- missForest(df,maxiter = maxiter,ntree = ntree,maxnodes = maxnodes,mtry = floor(sqrt(ncol(df))),parallelize = parallelize,verbose = verbose)$ximp}
else{ final <- missForest(df,maxiter = maxiter,ntree = ntree,maxnodes = maxnodes,mtry = mtry,parallelize = parallelize,verbose = verbose)$ximp}
}
#adding 0_1_cols
if (col_0_1){
columns_with_missing <-  (as.data.frame(is.na(df))*1)[,percent_of_missing>0]
colnames(columns_with_missing) <- paste(colnames(columns_with_missing),'where',sep='_')
final <- cbind(final,columns_with_missing)
}
# turn off paralllel
if (parallel){
registerDoSEQ()
}
return(final)
}
library(dplyr)
library(janitor)
library(tidyselect)
require(EMMA)
library(mlr3learners)
library(OpenML)
##### DO ZMIANY#####
OutLogLocation <- getwd()
outfilename <- '/out_log.txt'
preprocess <- function(df_oml, miss_in_var_threshold = 0.9) {
### Params
# - df_oml: object from getOMLDataSet()
# - miss_in_var_threshold: values [0, 1]; defines threshold of missings in columns to remove
### Output
# - df: ready, cleaned dataframe
# - data_types_troubles: flag for column types trouble
# - miss_in_target: flag for missing values in target variable
df <- df_oml$data
df_desc <- df_oml$desc
id <- df_desc$id
### Preprocessing step ###
check_type <- function(x){
is.numeric(x) | is.factor(x)
}
#Flags
data_types_troubles <- FALSE
miss_in_target <- FALSE
#Columns to ignore according to tags
to_ignore <- df_desc$ignore.attribute
if (all(!is.na(to_ignore))) {
df <- select(df,-all_of(to_ignore))
}
#Removing row ID column according to tags
row_id <- df_desc$row.id.attribute
row_id <- row_id[!row_id %in% to_ignore]
if (all(!is.na(row_id))) {
df <- select(df,-all_of(row_id))
}
#Data types
data_types_check <- sapply(df, check_type)
if (any(!data_types_check)) {
wrong_columns <- colnames(df)[!data_types_check]
#Trying possible conversions
for (col in wrong_columns) {
if (is.logical(df[, col]) | is.character(df[, col])) {
df[, col] <- as.factor(df[, col])
} else{
warning(paste("Data type trouble ID: ", id))
data_types_troubles <- TRUE
}
}
}
#Removing possible duplicate rows
df <- df[!duplicated(df),]
#Removing constant columns
df <- remove_constant(df)
#Removing empty columns
df <- remove_empty(df, "cols")
#All to lowercase
df <- mutate_if(df, is.factor, function(x)
factor(tolower(x)))
#Missing values in target variable
target <- df_oml$target.features
if (any(is.na(df[, target]))) {
miss_in_target <- TRUE
warning(paste("Missing values in target variable ID: ", id))
}
#Removing columns with % of missing higher than "miss_in_var_threshold"
df <- df[, which(colMeans(!is.na(df)) > miss_in_var_threshold)]
#Categorical columns with high fraction of unique values
#?
return(list("df" = df,
"data_types_troubles" = data_types_troubles,
"miss_in_target" = miss_in_target))
}
#######
out_file <- paste0(OutLogLocation,outfilename)
datasets_Ids <- c(4,15,25,38,802,930,957,961,40945,41162)
write(paste0('LOG',Sys.Date()),file = out_file)
check_type <- function(x){
is.numeric(x) | is.factor(x)
}
data_types_troubles <- c()
miss_in_target <- c()
list_of_pipe <- c(PipeOpMice$new(),PipeOpMissMDA_MFA$new(),PipeOpMissMDA_PCA_MCA_FMAD$new(),PipeOpmissForest$new(),PipeOpVIM_HD$new(),PipeOpVIM_IRMI$new(),
PipeOpVIM_kNN$new())
for(id in datasets_Ids){
df_oml <- getOMLDataSet(id)
df <- preprocess(df_oml,0.9)[[1]]
col_type <- 1:ncol(df)
for ( i in col_type){
col_type[i] <- class(df[,i])
}
percent_of_missing  <- 1:ncol(df)
for ( i in percent_of_missing){
percent_of_missing[i] <- (sum(is.na(df[,i]))/length(df[,1]))*100
}
write('----------------------IMPUTACJE-----------------------',append = T,file=out_file)
single_set_Pipeline(df,id,col_type,percent_of_missing,out_file_location = out_file,single_set = FALSE)
write('----------------------PIPLINE-----------------------',append = T,file=out_file)
for (i in list_of_pipe){
learner_po = po("learner", learner = lrn("classif.glmnet"))
test = i  %>>%  learner_po
glrn =GraphLearner$new(test)
test_task = TaskClassif$new('test',backend = df,target = df_oml$target.features)
cat(i$id,file = out_file,append = T)
tryCatch({
resample(test_task,glrn,rsmp('cv',folds=2L))
write(':  OK',file = out_file,append = T)
},error = function(e) { write(as.character(e),file=out_file,append = TRUE)})
}
}
df_oml <- getOMLDataSet(15)
df <- preprocess(df_oml,0.9)[[1]]
df_oml <- getOMLDataSet(15)
df <- preprocess(df_oml,0.9)[[1]]
col_type <- 1:ncol(df)
for ( i in col_type){
col_type[i] <- class(df[,i])
}
percent_of_missing  <- 1:ncol(df)
for ( i in percent_of_missing){
percent_of_missing[i] <- (sum(is.na(df[,i]))/length(df[,1]))*100
}
autotune_missForest(df,percent_of_missing)
#' Perform imputation using missForest form missForest package.
#'
#' @description Function use missForest package for data imputation. Function use OBBerror (more in missForest documentation) to perform grid search.
#' Best parameters to imputation are chosen form given sets. Imputation use parallel calculation by default and use existing parallel backend if it's possible.
#' If not function starts new parallel backend. !!!! Function doesn't turn off parallel backend by default after imputation. !!!!
#'
#'
#' @param df data.frame. Df to impute with column names and without  target column.
#' @param percent_of_missing numeric vector. Vector contatining percent of missing data in columns for example  c(0,1,0,0,11.3,..)
#' @param cores integer.  Number of threads used by parallel calculations. By default approximately half of available CPU cores.
#' @param ntree_set integer vector. Vector contains numbers of tree for grid search.
#' @param mtry_set integer vector. Vector contains numbers of variables randomly sampled at each split.
#' @param parallel logical. If TRUE parallel calculation is using.
#' @param optimize optimize inside function
#' @param ntree ntree from missForest function
#' @param mtry mtry form missforest function
#' @param verbose If FALSE funtion didn't print on console.
#' @param maxiter maxiter form missForest function.
#' @param maxnodes maxnodes from missForest function.
#' @import missForest
#' @import doParallel
#' @param col_0_1 decide if add bonus column informing where imputation been done. 0 - value was in dataset, 1 - value was imputed. Default False.
#'
#' @return Return data.frame with imputed values.
autotune_missForest <-function(df,percent_of_missing,cores=NULL,ntree_set =c(100,200,500,1000),mtry_set=NULL,parallel=TRUE,col_0_1=FALSE,
optimize=TRUE,ntree=100,mtry=NULL,verbose=FALSE,maxiter=20,maxnodes=NULL){
# Checking if parallel backed is runing and starting it if not
if (parallel){
veribles = ncol(df)
if (ceiling(detectCores()/2)>=veribles){cores <- (veribles-2)}
registerDoParallel(cores = cores)
}
# Prepering mtry_set if not given
if (is.null(mtry_set)){
mtry_set <- 1:4
mtry_set[1] <- floor(sqrt(ncol(df)))
if (mtry_set[1]>1){
mtry_set[2] <- ceiling(mtry_set[1]/2)
vector <- (mtry_set[1]:ncol(df))
mtry_set[3] <- floor(length(vector)/3)
mtry_set[4] <- floor(2*length(vector)/3)
}
else{
vector <- (mtry_set[1]:ncol(df))
mtry_set[2] <- floor(length(vector)/4)
mtry_set[3] <- floor(2*length(vector)/4)
mtry_set[4] <- floor(3*length(vector)/4)
}
}
# If parallel=TRUE
parallelize <- 'no'
if (parallel){
parallelize <-  'variables'}
if (!is.null(cores)){
if(cores<=1){parallelize <- 'no'}}
if (optimize){
# Grid search using mean OBBerror
best_params <-  c(-11,-11)
best_OBB <- 10
for (i in ntree_set)
{
for (j in mtry_set){
skip_to_next <- FALSE
tryCatch({
iteration <-  mean(missForest(df,maxiter = maxiter,ntree = i,mtry = j,parallelize=parallelize,maxnodes = maxnodes,verbose = verbose)$OOBerror)
if (iteration<best_OBB){
best_OBB <- iteration
best_params[1] <- i
best_params[2] <- j
}
}, error = function(e) { skip_to_next <<- TRUE})
if(skip_to_next) { next }
}
}
#fianl imputation
final <- missForest(df,maxiter = maxiter,maxnodes = maxnodes,ntree = best_params[1],mtry = best_params[2],parallelize=parallelize,verbose = verbose)$ximp
}
if (!optimize){
if (is.null(mtry)){
final <- missForest(df,maxiter = maxiter,ntree = ntree,maxnodes = maxnodes,mtry = floor(sqrt(ncol(df))),parallelize = parallelize,verbose = verbose)$ximp}
else{ final <- missForest(df,maxiter = maxiter,ntree = ntree,maxnodes = maxnodes,mtry = mtry,parallelize = parallelize,verbose = verbose)$ximp}
}
#adding 0_1_cols
if (col_0_1){
columns_with_missing <-  (as.data.frame(is.na(df))*1)[,percent_of_missing>0]
colnames(columns_with_missing) <- paste(colnames(columns_with_missing),'where',sep='_')
final <- cbind(final,columns_with_missing)
}
# turn off paralllel
if (parallel){
registerDoSEQ()
}
return(final)
}
autotune_missForest(df,percent_of_missing)
library(dplyr)
library(janitor)
library(tidyselect)
require(EMMA)
library(mlr3learners)
library(OpenML)
##### DO ZMIANY#####
OutLogLocation <- getwd()
outfilename <- '/out_log.txt'
preprocess <- function(df_oml, miss_in_var_threshold = 0.9) {
### Params
# - df_oml: object from getOMLDataSet()
# - miss_in_var_threshold: values [0, 1]; defines threshold of missings in columns to remove
### Output
# - df: ready, cleaned dataframe
# - data_types_troubles: flag for column types trouble
# - miss_in_target: flag for missing values in target variable
df <- df_oml$data
df_desc <- df_oml$desc
id <- df_desc$id
### Preprocessing step ###
check_type <- function(x){
is.numeric(x) | is.factor(x)
}
#Flags
data_types_troubles <- FALSE
miss_in_target <- FALSE
#Columns to ignore according to tags
to_ignore <- df_desc$ignore.attribute
if (all(!is.na(to_ignore))) {
df <- select(df,-all_of(to_ignore))
}
#Removing row ID column according to tags
row_id <- df_desc$row.id.attribute
row_id <- row_id[!row_id %in% to_ignore]
if (all(!is.na(row_id))) {
df <- select(df,-all_of(row_id))
}
#Data types
data_types_check <- sapply(df, check_type)
if (any(!data_types_check)) {
wrong_columns <- colnames(df)[!data_types_check]
#Trying possible conversions
for (col in wrong_columns) {
if (is.logical(df[, col]) | is.character(df[, col])) {
df[, col] <- as.factor(df[, col])
} else{
warning(paste("Data type trouble ID: ", id))
data_types_troubles <- TRUE
}
}
}
#Removing possible duplicate rows
df <- df[!duplicated(df),]
#Removing constant columns
df <- remove_constant(df)
#Removing empty columns
df <- remove_empty(df, "cols")
#All to lowercase
df <- mutate_if(df, is.factor, function(x)
factor(tolower(x)))
#Missing values in target variable
target <- df_oml$target.features
if (any(is.na(df[, target]))) {
miss_in_target <- TRUE
warning(paste("Missing values in target variable ID: ", id))
}
#Removing columns with % of missing higher than "miss_in_var_threshold"
df <- df[, which(colMeans(!is.na(df)) > miss_in_var_threshold)]
#Categorical columns with high fraction of unique values
#?
return(list("df" = df,
"data_types_troubles" = data_types_troubles,
"miss_in_target" = miss_in_target))
}
#######
out_file <- paste0(OutLogLocation,outfilename)
datasets_Ids <- c(4,15,25,38,802,930,957,961,40945,41162)
write(paste0('LOG',Sys.Date()),file = out_file)
check_type <- function(x){
is.numeric(x) | is.factor(x)
}
data_types_troubles <- c()
miss_in_target <- c()
list_of_pipe <- c(PipeOpMice$new(),PipeOpMissMDA_MFA$new(),PipeOpMissMDA_PCA_MCA_FMAD$new(),PipeOpmissForest$new(),PipeOpVIM_HD$new(),PipeOpVIM_IRMI$new(),
PipeOpVIM_kNN$new())
for(id in datasets_Ids){
df_oml <- getOMLDataSet(id)
df <- preprocess(df_oml,0.9)[[1]]
col_type <- 1:ncol(df)
for ( i in col_type){
col_type[i] <- class(df[,i])
}
percent_of_missing  <- 1:ncol(df)
for ( i in percent_of_missing){
percent_of_missing[i] <- (sum(is.na(df[,i]))/length(df[,1]))*100
}
write('----------------------IMPUTACJE-----------------------',append = T,file=out_file)
single_set_Pipeline(df,id,col_type,percent_of_missing,out_file_location = out_file,single_set = FALSE)
write('----------------------PIPLINE-----------------------',append = T,file=out_file)
for (i in list_of_pipe){
learner_po = po("learner", learner = lrn("classif.glmnet"))
test = i  %>>%  learner_po
glrn =GraphLearner$new(test)
test_task = TaskClassif$new('test',backend = df,target = df_oml$target.features)
cat(i$id,file = out_file,append = T)
tryCatch({
resample(test_task,glrn,rsmp('cv',folds=2L))
write(':  OK',file = out_file,append = T)
},error = function(e) { write(as.character(e),file=out_file,append = TRUE)})
}
}
library(dplyr)
library(janitor)
library(tidyselect)
require(EMMA)
library(mlr3learners)
library(OpenML)
##### DO ZMIANY#####
OutLogLocation <- getwd()
outfilename <- '/out_log.txt'
preprocess <- function(df_oml, miss_in_var_threshold = 0.9) {
### Params
# - df_oml: object from getOMLDataSet()
# - miss_in_var_threshold: values [0, 1]; defines threshold of missings in columns to remove
### Output
# - df: ready, cleaned dataframe
# - data_types_troubles: flag for column types trouble
# - miss_in_target: flag for missing values in target variable
df <- df_oml$data
df_desc <- df_oml$desc
id <- df_desc$id
### Preprocessing step ###
check_type <- function(x){
is.numeric(x) | is.factor(x)
}
#Flags
data_types_troubles <- FALSE
miss_in_target <- FALSE
#Columns to ignore according to tags
to_ignore <- df_desc$ignore.attribute
if (all(!is.na(to_ignore))) {
df <- select(df,-all_of(to_ignore))
}
#Removing row ID column according to tags
row_id <- df_desc$row.id.attribute
row_id <- row_id[!row_id %in% to_ignore]
if (all(!is.na(row_id))) {
df <- select(df,-all_of(row_id))
}
#Data types
data_types_check <- sapply(df, check_type)
if (any(!data_types_check)) {
wrong_columns <- colnames(df)[!data_types_check]
#Trying possible conversions
for (col in wrong_columns) {
if (is.logical(df[, col]) | is.character(df[, col])) {
df[, col] <- as.factor(df[, col])
} else{
warning(paste("Data type trouble ID: ", id))
data_types_troubles <- TRUE
}
}
}
#Removing possible duplicate rows
df <- df[!duplicated(df),]
#Removing constant columns
df <- remove_constant(df)
#Removing empty columns
df <- remove_empty(df, "cols")
#All to lowercase
df <- mutate_if(df, is.factor, function(x)
factor(tolower(x)))
#Missing values in target variable
target <- df_oml$target.features
if (any(is.na(df[, target]))) {
miss_in_target <- TRUE
warning(paste("Missing values in target variable ID: ", id))
}
#Removing columns with % of missing higher than "miss_in_var_threshold"
df <- df[, which(colMeans(!is.na(df)) > miss_in_var_threshold)]
#Categorical columns with high fraction of unique values
#?
return(list("df" = df,
"data_types_troubles" = data_types_troubles,
"miss_in_target" = miss_in_target))
}
#######
out_file <- paste0(OutLogLocation,outfilename)
datasets_Ids <- c(4,15,25,38,802,930,957,961,40945,41162)
write(paste0('LOG',Sys.Date()),file = out_file)
check_type <- function(x){
is.numeric(x) | is.factor(x)
}
data_types_troubles <- c()
miss_in_target <- c()
list_of_pipe <- c(PipeOpMice$new(),PipeOpMissMDA_MFA$new(),PipeOpMissMDA_PCA_MCA_FMAD$new(),PipeOpmissForest$new(),PipeOpVIM_HD$new(),PipeOpVIM_IRMI$new(),
PipeOpVIM_kNN$new())
for(id in datasets_Ids){
df_oml <- getOMLDataSet(id)
df <- preprocess(df_oml,0.9)[[1]]
col_type <- 1:ncol(df)
for ( i in col_type){
col_type[i] <- class(df[,i])
}
percent_of_missing  <- 1:ncol(df)
for ( i in percent_of_missing){
percent_of_missing[i] <- (sum(is.na(df[,i]))/length(df[,1]))*100
}
write('----------------------IMPUTACJE-----------------------',append = T,file=out_file)
single_set_Pipeline(df,id,col_type,percent_of_missing,out_file_location = out_file,single_set = FALSE)
write('----------------------PIPLINE-----------------------',append = T,file=out_file)
for (i in list_of_pipe){
learner_po = po("learner", learner = lrn("classif.rpart"))
test = i  %>>%  learner_po
glrn =GraphLearner$new(test)
test_task = TaskClassif$new('test',backend = df,target = df_oml$target.features)
cat(i$id,file = out_file,append = T)
tryCatch({
resample(test_task,glrn,rsmp('cv',folds=2L))
write(':  OK',file = out_file,append = T)
},error = function(e) { write(as.character(e),file=out_file,append = TRUE)})
}
}
learner_po = po("learner", learner = lrn("classif.rpart"))
library(EMMA)
