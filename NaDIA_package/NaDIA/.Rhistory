"iter" = ParamInt$new("iter", lower = 1, upper = Inf, default = 5, tags = "mice"),
"m" = ParamInt$new("m", lower = 1, upper = Inf, default = 2, tags = "mice"),
"maxit" = ParamInt$new("maxit", lower = 5, upper = 100, default = 5, tags = "mice"),
"set_method" = ParamUty$new("set_method", default = "pmm", tags = "mice"),
"low_corr" = ParamDbl$new("low_corr", lower = 0, upper = 1, default = 0, tags = "mice"),
"up_corr" = ParamDbl$new("up_corr", lower = 0, upper = 1, default = 1, tags = "mice"),
"methods_random" = ParamUty$new("methods_random", default = c("pmm"), tag = "mice"),
"random.seed" = ParamInt$new("random.seed", -Inf, Inf, default = 123, tags = "mice"),
"optimize" = ParamLgl$new("optimize", default = F, tags = "mice"),
"correlation" = ParamLgl$new("correlation", default = F, tags = "mice"),
"out_file" = ParamUty$new("out_file", default = NULL, tags = "mice")
))
)
self$imputed <- FALSE
self$column_counter <- NULL
self$data_imputed <- NULL
}), private = list(
.train_imputer = function(feature, type, context) {
imp_function <- function(data_to_impute) {
data_to_impute <- as.data.frame(data_to_impute)
# prepering arguments for function
col_type <- 1:ncol(data_to_impute)
for (i in col_type) {
col_type[i] <- class(data_to_impute[, i])
}
percent_of_missing <- 1:ncol(data_to_impute)
for (i in percent_of_missing) {
percent_of_missing[i] <- (sum(is.na(data_to_impute[, i])) / length(data_to_impute[, 1])) * 100
}
col_miss <- colnames(data_to_impute)[percent_of_missing > 0]
col_no_miss <- colnames(data_to_impute)[percent_of_missing == 0]
browser()
data_imputed <- EMMA::autotune_mice(data_to_impute,
col_miss = col_miss, col_no_miss = col_no_miss, col_type = col_type,
percent_of_missing = percent_of_missing, m = self$param_set$values$m, iter = self$param_set$values$iter,
maxit = self$param_set$values$maxit,
low_corr = self$param_set$values$low_corr, up_corr = self$param_set$values$up_corr,
set_cor = self$param_set$values$set_cor, set_method = self$param_set$values$set_method,
methods_random = self$param_set$values$methods_random, random.seed = self$param_set$values$random.seed,
optimize = self$param_set$values$optimize,
correlation = self$param_set$values$correlation, verbose = FALSE,
out_file = self$param_set$values$out_file, return_one = TRUE
)
return(data_imputed)
}
self$imputed_predict <- TRUE
self$flag <- "train"
if (!self$imputed) {
self$column_counter <- ncol(context) + 1
self$imputed <- TRUE
data_to_impute <- cbind(feature, context)
self$data_imputed <- imp_function(data_to_impute)
colnames(self$data_imputed) <- self$state$context_cols
}
if (self$imputed) {
self$column_counter <- self$column_counter - 1
}
if (self$column_counter == 0) {
self$imputed <- FALSE
}
self$train_s <- TRUE
self$action <- 3
model <- list("data_imputed" = self$data_imputed, "train_s" = self$train_s, "flag" = self$flag, "imputed_predict" = self$imputed_predict, "imputed" = self$imputed, "column_counter" = self$column_counter)
return(model)
},
.impute = function(feature, type, model, context) {
if (is.null(self$action)) {
self$train_s <- model$train_s
self$flag <- model$flag
self$imputed_predict <- model$imputed_predict
self$action <- 3
self$data_imputed <- model$data_imputed
self$imputed <- F
self$column_counter <- model$column_counter
}
imp_function <- function(data_to_impute) {
data_to_impute <- as.data.frame(data_to_impute)
# prepering arguments for function
col_type <- 1:ncol(data_to_impute)
for (i in col_type) {
col_type[i] <- class(data_to_impute[, i])
}
percent_of_missing <- 1:ncol(data_to_impute)
for (i in percent_of_missing) {
percent_of_missing[i] <- (sum(is.na(data_to_impute[, i])) / length(data_to_impute[, 1])) * 100
}
col_miss <- colnames(data_to_impute)[percent_of_missing > 0]
col_no_miss <- colnames(data_to_impute)[percent_of_missing == 0]
data_imputed <- EMMA::autotune_mice(data_to_impute,
col_miss = col_miss, col_no_miss = col_no_miss, col_type = col_type,
percent_of_missing = percent_of_missing, m = self$param_set$values$m, iter = self$param_set$values$iter,
maxit = self$param_set$values$maxit,
low_corr = self$param_set$values$low_corr, up_corr = self$param_set$values$up_corr,
set_cor = self$param_set$values$set_cor, set_method = self$param_set$values$set_method,
methods_random = self$param_set$values$methods_random, random.seed = self$param_set$values$random.seed,
optimize = self$param_set$values$optimize,
correlation = self$param_set$values$correlation, verbose = F,
out_file = self$param_set$values$out_file, return_one = T
)
return(data_imputed)
}
if (self$imputed) {
feature <- self$data_imputed[, setdiff(colnames(self$data_imputed), colnames(context))]
}
if ((nrow(self$data_imputed) != nrow(context) | !self$train_s) & self$flag == "train") {
self$imputed_predict <- FALSE
self$flag <- "predict"
}
if (!self$imputed_predict) {
data_to_impute <- cbind(feature, context)
self$data_imputed <- imp_function(data_to_impute)
colnames(self$data_imputed)[1] <- setdiff(self$state$context_cols, colnames(context))
self$imputed_predict <- TRUE
}
if (self$imputed_predict & self$flag == "predict") {
feature <- self$data_imputed[, setdiff(colnames(self$data_imputed), colnames(context))]
}
if (self$column_counter == 0 & self$flag == "train") {
feature <- self$data_imputed[, setdiff(colnames(self$data_imputed), colnames(context))]
self$flag <- "predict"
self$imputed_predict <- FALSE
}
self$train_s <- FALSE
return(feature)
}
)
)
oml_task <- OMLTask$new(3021)
task <- oml_task$task
pipe_model <- lrn("classif.glmnet")
graph <-
PipeOpMice$new() %>>%
pipe_model
graph_learner <- GraphLearner$new(graph)
graph_learner$param_set$values$impute_mice_B.set_method <- 'cart'
resample(task,graph_learner,rsmp('cv',folds=5))
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
include = FALSE
)
library(EMMA)
# Creating operator implementing imputatio method
imputation_methods <- PipeOpMice$new()
# task with missing data from mlr3
task_with_missing <- tsk('pima')
task_with_missing$missings(
)
# Creating operator implementing imputatio method
imputation_methods <- PipeOpMice$new()
#  Imputation
task_with_no_missing <- imputation_methods$train(list(task_with_missing))
task_with_no_missing$missings()
# task with missing data from mlr3
task_with_missing <- tsk('pima')
task_with_missing$missings(
)
# Creating operator implementing imputatio method
imputation_methods <- PipeOpMice$new()
#  Imputation
task_with_no_missing <- imputation_methods$train(list(task_with_missing))
task_with_no_missing$missings()
library(EMMA)
# task with missing data from mlr3
task_with_missing <- tsk('pima')
task_with_missing$missings(
)
# Creating operator implementing imputatio method
imputation_methods <- PipeOpMice$new()
#  Imputation
task_with_no_missing <- imputation_methods$train(list(task_with_missing))
task_with_no_missing$missings()
task_with_missing$missings()
#  Imputation
task_with_no_missing <- imputation_methods$train(list(task_with_missing))
task_with_no_missing$missings()
#  Imputation
task_with_no_missing <- imputation_methods$train(list(task_with_missing))[[1]]
function(data_to_impute) {
data_to_impute <- as.data.frame(data_to_impute)
# prepering arguments for function
col_type <- 1:ncol(data_to_impute)
for (i in col_type) {
col_type[i] <- class(data_to_impute[, i])
}
percent_of_missing <- 1:ncol(data_to_impute)
for (i in percent_of_missing) {
percent_of_missing[i] <- (sum(is.na(data_to_impute[, i])) / length(data_to_impute[, 1])) * 100
}
col_miss <- colnames(data_to_impute)[percent_of_missing > 0]
col_no_miss <- colnames(data_to_impute)[percent_of_missing == 0]
browser()
data_imputed <- EMMA::autotune_mice(data_to_impute,
col_miss = col_miss, col_no_miss = col_no_miss, col_type = col_type,
percent_of_missing = percent_of_missing, m = self$param_set$values$m, iter = self$param_set$values$iter,
maxit = self$param_set$values$maxit,
low_corr = self$param_set$values$low_corr, up_corr = self$param_set$values$up_corr,
set_cor = self$param_set$values$set_cor, set_method = self$param_set$values$set_method,
methods_random = self$param_set$values$methods_random, random.seed = self$param_set$values$random.seed,
optimize = self$param_set$values$optimize,
correlation = self$param_set$values$correlation, verbose = FALSE,
out_file = self$param_set$values$out_file, return_one = TRUE
)
return(data_imputed)
}
# Creating operator implementing imputatio method
imputation_methods <- PipeOpMice$new()
library(EMMA)
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
include = FALSE
)
library(EMMA)
# task with missing data from mlr3
task_with_missing <- tsk('pima')
task_with_missing$missings()
# Creating operator implementing imputatio method
imputation_methods <- PipeOpMice$new()
#  Imputation
task_with_no_missing <- imputation_methods$train(list(task_with_missing))[[1]]
View(data_to_impute)
task_with_no_missing$missings()
```{r, include = FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
include = FALSE
)
library(EMMA)
# task with missing data from mlr3
task_with_missing <- tsk('pima')
task_with_missing$missings()
# Creating operator implementing imputatio method
imputation_methods <- PipeOpMice$new()
#  Imputation
task_with_no_missing <- imputation_methods$train(list(task_with_missing))[[1]]
task_with_no_missing$missings()
imp_function <- function(data_to_impute) {
data_to_impute <- as.data.frame(data_to_impute)
# prepering arguments for function
col_type <- 1:ncol(data_to_impute)
for (i in col_type) {
col_type[i] <- class(data_to_impute[, i])
}
percent_of_missing <- 1:ncol(data_to_impute)
for (i in percent_of_missing) {
percent_of_missing[i] <- (sum(is.na(data_to_impute[, i])) / length(data_to_impute[, 1])) * 100
}
col_miss <- colnames(data_to_impute)[percent_of_missing > 0]
col_no_miss <- colnames(data_to_impute)[percent_of_missing == 0]
data_imputed <- EMMA::autotune_mice(data_to_impute,
col_miss = col_miss, col_no_miss = col_no_miss, col_type = col_type,
percent_of_missing = percent_of_missing, m = self$param_set$values$m, iter = self$param_set$values$iter,
maxit = self$param_set$values$maxit,
low_corr = self$param_set$values$low_corr, up_corr = self$param_set$values$up_corr,
set_cor = self$param_set$values$set_cor, set_method = self$param_set$values$set_method,
methods_random = self$param_set$values$methods_random, random.seed = self$param_set$values$random.seed,
optimize = self$param_set$values$optimize,
correlation = self$param_set$values$correlation, verbose = FALSE,
out_file = self$param_set$values$out_file, return_one = TRUE
)
return(data_imputed)
}
# task with missing data from mlr3
task_with_missing <- tsk('pima')
task_with_missing$missings()
# Creating operator implementing imputatio method
imputation_methods <- PipeOpMice$new()
#  Imputation
task_with_no_missing <- imputation_methods$train(list(task_with_missing))[[1]]
task_with_no_missing$missings()
library(mlr3learners)
# Creting graph learnerg
# imputation method
imp <- PipeOpmissForest$new()
#encoder
encoder <- PipeOpEncodeImpact$new()
# learner
learner <- lrn('classif.glmnet')
graph <- imp %>>% encoder %>>% learner
graph_lerner <- GraphLearner$new(graph)
# resampling
set.seed(1)
resample(tsk('pima'),graph_lerner,rsmp('cv',folds=5))
task_problematic <- TaskClassif$new('task',data,'Species')
# Error hendling
graph_lerner$encapsulate <- c(train='evaluate',predict='evaluate')
#Creating problematic task
data <- iris
data[,1] <- NA
task_problematic <- TaskClassif$new('task',data,'Species')
rr <- resample(tsk('pima'),graph_lerner,rsmp('cv',folds=5))
# produced errors
rr$errors
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
include = FALSE
)
library(EMMA)
# Turning off encapsulation
graph_lerner$encapsulate <- c(train='none',predict='none')
# Turning on optimalization
graph_lerner$param_set$values$impute_missRanger_B.optimize <- TRUE
graph_lerner
library(mlr3learners)
# Creating graph learner
# imputation method
imp <- PipeOpmissRanger$new()
# encoder
encoder <- PipeOpEncodeImpact$new()
# learner
learner <- lrn('classif.glmnet')
graph <- imp %>>% encoder %>>% learner
graph_lerner <- GraphLearner$new(graph, id = 'missRanger.learner')
# resampling
set.seed(1)
resample(tsk('pima'),graph_lerner,rsmp('cv',folds=5))
# Error handling
graph_lerner$encapsulate <- c(train='evaluate',predict='evaluate')
# Creating a problematic task
data <- iris
data[,1] <- NA
task_problematic <- TaskClassif$new('task',data,'Species')
# Resampling
set.seed(1)
rr <- resample(task_problematic,graph_lerner,rsmp('cv',folds=5))
# All folds are tested and the script run forward
# Turning off encapsulation
graph_lerner$encapsulate <- c(train='none',predict='none')
# Turning on optimalization
graph_lerner$param_set$values$impute_missRanger_B.optimize <- TRUE
# Resampling
set.seed(1)
rr <- resample(tsk('pima'),graph_lerner,rsmp('cv',folds=5))
# Turning off encapsulation
graph_lerner$encapsulate <- c(train='none',predict='none')
# Turning on optimalization
graph_lerner$param_set$values$impute_missRanger_B.optimize <- TRUE
# Resampling
set.seed(1)
rr <- resample(tsk('pima'),graph_lerner,rsmp('cv',folds=5))
# Error handling
graph_lerner$encapsulate <- c(train='evaluate',predict='evaluate')
# Creating a problematic task
data <- iris
data[,1] <- NA
task_problematic <- TaskClassif$new('task',data,'Species')
# Resampling
set.seed(1)
rr <- resample(task_problematic,graph_lerner,rsmp('cv',folds=5))
# All folds are tested and the script run forward
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
include = FALSE
)
library(EMMA)
knitr::include_graphics('diagram.png')
# Task with missing data from mlr3
task_with_missing <- tsk('pima')
task_with_missing$missings()
# Creating an operator implementing the imputation method
imputation_methods <- PipeOpMice$new()
# Imputation
task_with_no_missing <- imputation_methods$train(list(task_with_missing))[[1]]
task_with_no_missing$missings()
library(mlr3learners)
# Creating graph learner
# imputation method
imp <- PipeOpmissRanger$new()
# encoder
encoder <- PipeOpEncodeImpact$new()
# learner
learner <- lrn('classif.glmnet')
graph <- imp %>>% encoder %>>% learner
graph_lerner <- GraphLearner$new(graph, id = 'missRanger.learner')
# resampling
set.seed(1)
resample(tsk('pima'),graph_lerner,rsmp('cv',folds=5))
# Error handling
graph_lerner$encapsulate <- c(train='evaluate',predict='evaluate')
# Creating a problematic task
data <- iris
data[,1] <- NA
task_problematic <- TaskClassif$new('task',data,'Species')
# Resampling
set.seed(1)
rr <- resample(task_problematic,graph_lerner,rsmp('cv',folds=5))
# All folds are tested and the script run forward
tsk('pima')
graph_lerner
rsmp('cv',folds=5)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
include = FALSE
)
library(EMMA)
knitr::include_graphics('diagram.png')
# Task with missing data from mlr3
task_with_missing <- tsk('pima')
task_with_missing$missings()
# Creating an operator implementing the imputation method
imputation_methods <- PipeOpMice$new()
# Imputation
task_with_no_missing <- imputation_methods$train(list(task_with_missing))[[1]]
task_with_no_missing$missings()
library(mlr3learners)
# Creating graph learner
# imputation method
imp <- PipeOpmissRanger$new()
# encoder
encoder <- PipeOpEncodeImpact$new()
# learner
learner <- lrn('classif.glmnet')
graph <- imp %>>% encoder %>>% learner
graph_lerner <- GraphLearner$new(graph, id = 'missRanger.learner')
# resampling
set.seed(1)
resample(tsk('pima'),graph_lerner,rsmp('cv',folds=5))
# Error handling
graph_lerner$encapsulate <- c(train='evaluate',predict='evaluate')
# Creating a problematic task
data <- iris
data[,1] <- NA
task_problematic <- TaskClassif$new('task',data,'Species')
# Resampling
set.seed(1)
rr <- resample(task_problematic,graph_lerner,rsmp('cv',folds=5))
# All folds are tested and the script run forward
# Turning off encapsulation
graph_lerner$encapsulate <- c(train='none',predict='none')
# Turning on optimalization
graph_lerner$param_set$values$impute_missRanger_B.optimize <- TRUE
print(graph_lerner)
# Resampling
set.seed(1)
rr <- resample(tsk('pima'),graph_lerner,rsmp('cv',folds=5))
# Turning off encapsulation
graph_lerner$encapsulate <- c(train='none',predict='none')
# Turning on optimalization
graph_lerner$param_set$values$impute_missRanger_B.optimize <- TRUE
# Resampling
set.seed(1)
resample(tsk('pima'),graph_lerner,rsmp('cv',folds=5))
# Creating graph learner
# imputation method
imp <- PipeOpMean_B$new()
# encoder
encoder <- PipeOpEncodeImpact$new()
# learner
learner <- lrn('classif.glmnet')
graph <- imp %>>% encoder %>>% learner
graph_lerner <- GraphLearner$new(graph)
# resampling
set.seed(1)
resample(tsk('pima'),graph_lerner,rsmp('cv',folds=5))
# Creating graph learner
# imputation method
imp <- PipeOpMean_B$new()
# encoder
encoder <- PipeOpEncodeImpact$new()
# learner
learner <- lrn('classif.glmnet')
graph <- imp %>>% encoder %>>% learner
graph_lerner <- GraphLearner$new(graph)
# resampling
set.seed(1)
resample(tsk('pima'),graph_lerner,rsmp('cv',folds=5))
# Error handling
graph_lerner$encapsulate <- c(train='evaluate',predict='evaluate')
# Creating a problematic task
data <- iris
data[,1] <- NA
task_problematic <- TaskClassif$new('task',data,'Species')
# Resampling
set.seed(1)
resample(task_problematic,graph_lerner,rsmp('cv',folds=5))
# All folds are tested and the script run forward
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(EMMA)
devtools::document()
library(EMMA)
devtools::document()
library(EMMA)
devtools::document()
devtools::document()
devtools::document()
devtools::document()
library(EMMA)
library(EMMA)
library(EMMA)
devtools::document()
devtools::document()
devtools::document()
